---
title: "Forecasting Stock Market Dynamics in the Tech Sector: A Multi-Stock Gradient Boosting Approach"
author: 
  - Jamie Lee
thanks: "Code and data are available at: https://github.com/jamiejiminlee/Tech-Stock-Forecast.git"
date: today
date-format: long
abstract: "First sentence. Second sentence. Third sentence. Fourth sentence."
format: pdf
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(ggplot2)
library(arrow)

price_analysis_data <- read_parquet("/Users/jamielee/TechStockForecast/data/02-analysis_data/analysis_data.parquet")
```


# Introduction

Overview paragraph

Estimand paragraph

Results paragraph

Why it matters paragraph

Telegraphing paragraph: The remainder of this paper is structured as follows. @sec-data....






# Data {#sec-data}

## Overview

The data for this paper, obtained from the Yahoo Finance API via the `tidyquant` library in R on November 19, 2024, encompasses historical stock price information for four leading technology companies: Google (GOOG), Apple (AAPL), Amazon (AMZN), and Microsoft (MSFT). This dataset spans from January 1, 2018, to December 31, 2024, providing daily stock market data for each company. Key variables include **`symbol`**, **`date`**, **`open`**, **`high`**, **`low`**, **`close`**, **`volume`**, and **`adjusted`** prices. Our analysis focuses on predicting daily price differences and percentage changes across this basket of stocks, leveraging additional features constructed from the raw dataset. These features include **`Price_Lag1`** (lagged closing prices), **`Price_Diff`** (daily price differences), and **`Price_Change_Percent`** (percentage changes). By incorporating these derived variables, we aim to capture sequential trends and normalize differences across stocks with varying price ranges.

To ensure reliability, the dataset was preprocessed to remove missing values, align timeframes across stocks, and compute the constructed variables. Observations with incomplete data were excluded to maintain consistency in analysis. Details on the data cleaning and feature construction process are provided in [Appendix -@sec-data-cleaning].

Data cleaning and analysis were conducted using the following packages: the `tidyverse` package of @Tidyverse, `lubridate` package of @Lubridate, and `arrow` package of @arrow. These tools facilitated efficient data manipulation, feature construction, and storage in a compact Parquet format for further analysis.
	
## Measurement

Stock prices are influenced by numerous factors, including macroeconomic conditions, industry trends, corporate actions, and investor sentiment. These dynamics fluctuate frequently, often in response to earnings reports, geopolitical events, or shifts in market expectations. Financial data simplifies these complex market behaviors into numerical indicators such as **`open`**, **`high`**, **`low`**, and **`close`** prices, which, while precise, may not fully encapsulate underlying investor motivations or market sentiment. For instance, the closing price represents only the last traded price of the day, smoothing out intraday volatility and obscuring more nuanced trading patterns.

Constructed variables like **`Price_Diff`** and **`Price_Change_Percent`** aim to quantify daily stock price movements by measuring differences or proportional changes relative to the previous day. However, these metrics assume that price movements reflect consistent investor sentiment across all stocks, potentially overlooking idiosyncratic factors specific to individual companies, such as leadership changes or product launches. Additionally, these metrics equally weight all days, despite certain trading days (e.g., earnings announcements or market holidays) being more influential.

The **`volume`** variable, representing the total shares traded, is used as a proxy for market activity and investor interest. This assumes that higher trading volumes uniformly indicate significant market events, despite possible differences in trading motives, such as speculative activity or algorithmic trading. Similarly, the temporal predictors, including **`date`**, **`day of the week`**, and **`month`**, aim to capture seasonal trends or trading patterns. However, these features simplify complex market behaviors into discrete time intervals, potentially overlooking shorter-term dynamics like market reactions to breaking news or macroeconomic data releases.

By aggregating these variables across a basket of stocks, the model assumes comparability among them, despite differences in market capitalization, industry focus, and investor bases. This simplification may obscure unique drivers of price changes for each stock, potentially limiting the model’s ability to capture more granular patterns. Nonetheless, these variables collectively provide a structured framework for analyzing and predicting daily price movements within the selected basket of stocks.


## Variables
The collected data from Yahoo Finance includes several key variables relevant to the analysis of price changes across a basket of tech stocks (**Google**, **Apple**, **Amazon**, and **Microsoft**). The original dataset contains the following columns:

- **`symbol`**: Represents the stock ticker symbol, identifying the company (e.g., GOOG for Google, AAPL for Apple).
- **`date`**: The trading date, essential for tracking and analyzing temporal patterns.
- **`open`**: The stock's opening price on a given day, providing context for daily price movements.
- **`high`**: The highest price of the stock during the trading day, useful for understanding intraday volatility.
- **`low`**: The lowest price of the stock during the trading day, another measure of volatility.
- **`close`**: The stock's closing price on a given day, which is a standard benchmark for daily performance.
- **`volume`**: The total number of shares traded during the day, reflecting market activity and investor interest.
- **`adjusted`**: The adjusted closing price, accounting for corporate actions like stock splits and dividends to provide a standardized measure of value.

In addition to these original variables, new features were constructed to enhance the analysis:

- **`Price_Lag1`**: Derived as the closing price from the previous trading day, enabling the analysis of sequential price changes.
- **`Price_Diff`**: Calculated as the difference between the current day’s closing price and the previous day’s closing price, capturing day-to-day fluctuations.
- **`Price_Change_Percent`**: Derived as the percentage change in stock price relative to the previous day's closing price, normalized to enable comparisons across stocks.

These constructed variables allow for a more detailed examination of stock price movements. To ensure high-quality analysis, the data was cleaned and preprocessed to remove missing values, align timeframes across stocks, and compute these derived features. For further details on the data cleaning and preparation process, refer to [Appendix -@sec-data-cleaning].

### Predictor Variables


Some of our data is of penguins (@fig-bills), from @palmerpenguins.

```{r}
#| label: fig-bills
#| fig-cap: Bills of penguins
#| echo: false

ggplot(penguins, aes(x = island, fill = species)) +
  geom_bar(alpha = 0.8) +
  scale_fill_manual(values = c("darkorange","purple","cyan4"),
                    guide = "none") +
  theme_minimal() +
  facet_wrap(~species, ncol = 1) +
  coord_flip()
```

Talk more about it.

And also planes (@fig-planes). (You can change the height and width, but don't worry about doing that until you have finished every other aspect of the paper - Quarto will try to make it look nice and the defaults usually work well once you have enough text.)

```{r}
#| label: fig-planes
#| fig-cap: Relationship between wing length and width
#| echo: false
#| warning: false
#| message: false

analysis_data <- read_csv(here::here("data/02-analysis_data/analysis_data.csv"))

analysis_data |> 
  ggplot(aes(x = width, y = length)) +
  geom_point(alpha = 0.8) +
  theme_minimal() +
  labs(x = "Wing width (mm)",
       y = "Wing length (mm)")
```

Talk way more about it. 

## Predictor variables

Add graphs, tables and text.

Use sub-sub-headings for each outcome variable and feel free to combine a few into one if they go together naturally.








# Model

The goal of our modelling strategy is twofold. Firstly,...

Here we briefly describe the Bayesian analysis model used to investigate... Background details and diagnostics are included in [Appendix -@sec-model-details].

## Model set-up

Define $y_i$ as the number of seconds that the plane remained aloft. Then $\beta_i$ is the wing width and $\gamma_i$ is the wing length, both measured in millimeters.  

\begin{align} 
y_i|\mu_i, \sigma &\sim \mbox{Normal}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_i + \gamma_i\\
\alpha &\sim \mbox{Normal}(0, 2.5) \\
\beta &\sim \mbox{Normal}(0, 2.5) \\
\gamma &\sim \mbox{Normal}(0, 2.5) \\
\sigma &\sim \mbox{Exponential}(1)
\end{align}

We run the model in R [@citeR] using the `rstanarm` package of @rstanarm. We use the default priors from `rstanarm`.


### Model justification

We expect a positive relationship between the size of the wings and time spent aloft. In particular...

We can use maths by including latex between dollar signs, for instance $\theta$.


# Results

Our results are summarized in @tbl-modelresults.

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false

library(rstanarm)

first_model <-
  readRDS(file = here::here("models/first_model.rds"))
```

```{r}
#| echo: false
#| eval: true
#| label: tbl-modelresults
#| tbl-cap: "Explanatory models of flight time based on wing width and wing length"
#| warning: false

modelsummary::modelsummary(
  list(
    "First model" = first_model
  ),
  statistic = "mad",
  fmt = 2
)
```




# Discussion

## First discussion point {#sec-first-point}

If my paper were 10 pages, then should be be at least 2.5 pages. The discussion is a chance to show off what you know and what you learnt from all this. 

## Second discussion point

Please don't use these as sub-heading labels - change them to be what your point actually is.

## Third discussion point

## Weaknesses and next steps

Weaknesses and next steps should also be included.

\newpage

\appendix

# Appendix {-}


# Additional data details

# Model details {#sec-model-details}

## Posterior predictive check

In @fig-ppcheckandposteriorvsprior-1 we implement a posterior predictive check. This shows...

In @fig-ppcheckandposteriorvsprior-2 we compare the posterior with the prior. This shows... 

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-ppcheckandposteriorvsprior
#| layout-ncol: 2
#| fig-cap: "Examining how the model fits, and is affected by, the data"
#| fig-subcap: ["Posterior prediction check", "Comparing the posterior with the prior"]

pp_check(first_model) +
  theme_classic() +
  theme(legend.position = "bottom")

posterior_vs_prior(first_model) +
  theme_minimal() +
  scale_color_brewer(palette = "Set1") +
  theme(legend.position = "bottom") +
  coord_flip()
```

## Diagnostics

@fig-stanareyouokay-1 is a trace plot. It shows... This suggests...

@fig-stanareyouokay-2 is a Rhat plot. It shows... This suggests...

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-stanareyouokay
#| fig-cap: "Checking the convergence of the MCMC algorithm"
#| fig-subcap: ["Trace plot", "Rhat plot"]
#| layout-ncol: 2

plot(first_model, "trace")

plot(first_model, "rhat")
```



\newpage


# References


